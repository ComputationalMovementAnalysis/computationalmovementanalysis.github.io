[["index.html", "Computational Movement Analysis: Patterns and Trends in Environmental Data Master ENR, Spring Semester 2022 Welcome to the course! License", " Computational Movement Analysis: Patterns and Trends in Environmental Data Master ENR, Spring Semester 2022 Patrick Laube, Nils Ratnaweera, Nikolaos Bakogiannis 01 Juni, 2022 Welcome to the course! For the practical part of the course, building-up skills for analysing movement data in the software environment R, youll be using data from the ZHAW project Prävention von Wildschweinschäden in der Landwirtschaft. The project investigates the spatiotemporal movement patterns of wild boar (Sus scrofa) in agricultural landscapes. We will study the trajectories of these wild boar, practising the most basic analysis tasks of Computational Movement Analysis (CMA). This video gives a nice introduction into the project License These R Exercises are created by Patrick Laube, Nils Ratnaweera and Nikolaos Bakogiannis for the Course *Computational Movement Analysis\" and are licensed under Creative Commons Attribution 4.0 International License. This work is licensed under a Creative Commons Attribution 4.0 International License. "],["W0_1_preparations.html", "Preparation Install or update R Install or update RStudio Install the necessary packages Install Git Configure RStudio Introduce yourself to Git", " Preparation In this course we will be using R, RStudio and Git. We ask you to install and/or update these programs before the start of the course, so that we do not loose time once the course starts. In this chapter, we cover the course requirements and some tips on how you should change your RStudio settings. Install or update R If you havent installed R yet, do so now by getting the newest version from CRAN. If you do have R installed, check your Version of R by opening RStudio and typing the following command into the console. R.version.string ## [1] &quot;R version 4.1.3 (2022-03-10)&quot; This returns the version number of your R installation, whereas the first digit (4) indicates the number of the major release, the second digit (1) indicates the minor release and the last digit (3) refers to the patch release. As a general rule of thumb, you will want to update R if you dont have the current major version or are lagging two (or more) versions behind the current minor release In the time of writing (Juni, 2022), the current R Version is 4.2.0 (released on 2022-04-22 07:05:41, see cran.r-project.org). Your installation should therefore not be older than 4.1.0. If it is, make sure that you have updated R before the course. Check these instructions on how to update R Install or update RStudio RStudio is the IDE (integrated development environment) we use in our course to interact with R. There are good alternatives you can use, RStudio simply seems to be the most popular choice. If you want to use your own IDE, please feel free to do so. However, we dont recommend this if you are a beginner. We recommend updating RStudio to the newest version before the course: check if this is the case by clicking on help &gt; check for updates. Hey #rstats community. Im doing research - what is your favorite way to code in #R?  Matt Dancho (Business Science) ((mdancho84?)) March 11, 2022 Install the necessary packages In the course, we will be needing the following packages (amongst others). Save time during the course by installing these upfront! Check if you can load the packages by calling library(dplyr) (note the missing \"). install.packages(&quot;rmarkdown&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;ggplot2&quot;) install.packages(&quot;readr&quot;) install.packages(&quot;tidyr&quot;) install.packages(&quot;sf&quot;) install.packages(&quot;terra&quot;) Install Git Git is a software dedicated to tracking changes in text files (e.g. R scripts). Its heavily used in the software industry as well as in the field of data science. In this course, we will teach use the basic functionalities of Git and combine it with the online portal Github. Therefore, the next step is to install Git. There are different Git installers to choose from, we recommend the following: Windows: We recommend installing Git for Windows, also known as msysgit or Git Bash. When asked about Adjusting your PATH environment, select Git from the command line and also from 3rd-party software RStudio prefers Git to be installed in C:/Program Files/Git, we recommend following this convention Otherwise, we believe it is good to accept the defaults macOS: We recommend you install the Xcode command line tools (not all of Xcode), which includes Git Go to the shell and enter xcode-select --install to install developer command line tools Linux: On Ubuntu or Debian Linux: sudo apt-get install git On Fedora or RedHat Linux: sudo yum install git Much of this chapter was taken from Bryan and Heister (2021). If you want to dive deeper into using Git, we highly recommend this book. For an even deeper dive into Git, read Chacon and Straub (2014). Both books are available free and open source on happygitwithr.com and git-scm.com/book, respectively. Configure RStudio Now we will set some RStudio Global options. But first, close all instances of RStudio and restart it (!!!). Then go to Tools &gt; Global options. R General Deactivate the option Restore .RData into workspace at startup1 Set Save workspace to .RData on exit to Never2 Git / SVN Activate the option Enable version control interface for RStudio projects If the Field Git executable: shows (Not Found), browse to your git installation (previous step). This path should look something like this: Windows: C:/Program Files/Git/bin/git.exe (not C:/Program Files/Git/cmd/git.exe or some-path/git-bash.exe) Linux / macOS: /usr/bin/git Terminal Set option New terminals open with to Git Bash Click on Ok to apply the change and close the options menu. Introduce yourself to Git Now it is time to introduce yourself to git. For this, we need to use the shell terminal, which is why we are going to spend a few word on the shell first. The shell is a program on your computer whose job is to run other programs. It looks very much like the R-console (in the bottom left of RStudio) that you are already know: You have a place to input text which is transferred to (and interpreted by) the computer when you press enter. RStudio has a shell terminal right next to the R-console (tab Terminal). Every Windows comes with two different shell installations: Command prompt and PowerShell. After installing Git we now have a third option, Git Bash. The shell terminal in RStudio uses Command prompt per default, in the last step we just switched the shell to Git Bash. Now use the terminal in RStudio to introduce yourself: git config --global user.name &quot;Maria Nusslinger&quot; git config --global user.email &quot;nussmar@email.com&quot; Of course, replace the name and address with your credentials. Use the email address that you will use to create your Github account (which we will do next week). Note to users who already have a Github account: If you already have a Github account and dont want to associate the work you do in this course with said account, we recommend the following approach: Create a new Github account with a different mailaddress (e.g. your student mail address) Override your user.name and user.email on a per project basis (by omitting the --global flag) Please feel free to contact us if you have questions about this. We recommend that you start each RStudio session with a blank slate, as recommended by Wickham and Grolemund (2017) see here If we dont restore the workspace at startup, there is no need to save it on exit. "],["W1_1_exercise.html", "Exercise 1", " Exercise 1 This exercise covers the necessary steps for getting ready in R and some basic concepts for setting up a well-structured R project. The lesson introduces how additional packages that provide useful functions for data science are made available and how spatial data is handled. The exercise concludes with the creation of your first map featuring movement data. Learning Outcomes* You learn how to structure an R project. You can read movement data from a .csv-file into a data.frame You can convert spatial point data from a data.frame to a spatial object sf You can perform basic spatial operations on spatial objects in R You can produce simple maps of your spatial data using ggplot2 You can produce simple maps of your spatial data using tmap "],["W1_4_preparation.html", "Preparation", " Preparation Folder structure for this course By this point, you probably have created a folder for this course somewhere on your computer. In our example, we assume this folder is located here: C:/Users/yourname/semester1/Modul_CMA (mentally replace this with your actual path). Before we dive into the exercises, take a minute to think about how you are going to structure your files in this folder. This course will take place over 6 weeks, and in each week you will receive or produce various files. We recommend creating a separate folder for each week, and one folder for the semester project, like so: Course Folder (C:\\\\Users\\\\yourname\\\\semester1\\\\Modul_CMA) ¦--week1 ¦--week2 ¦--week3 ¦--week4 ¦--week5 ¦--week6 °--semester_project For the R-exercises that take place in weeks 1 to 5, we recommend that you create a new RStudio Project each week in subdirectory of the appropriate week. For example, this week your folder structure could look like this: Folder Week 1 (C:\\\\Users\\\\yourname\\\\semester2\\\\Modul_CMA\\\\week1) ¦--slides.pdf ¦--my_notes.docx ¦--seminar_screenshot.jpg °--week0-rexercise ¦--week0-rexercise.Rproj ¦--wildschwein_BE.csv °--my_solution.Rmd Note: the RStudio Project is located in a subfolder of `and namedweek1-rexercise`. week1-rexercise is the projects directory name and the project name we realize that that the week number is redundant, there is a reason3 for this this means each week is a fresh start (which has pros and cons) Create an RStudio project for the first week Create a new RStudio Project (File &gt; New Project &gt; New Directory &gt; New Project). Click on Browse and switch to your equivalent of the folder `` (the project we are about to initiate will be be created in a subdirectory of this folder). Click on open to confirm the selection In the field Directory name, type week1-rexercise. This will be the name of your RStudio project and its parent directory. Check the option Create a git repository Click on Create Project You are all set! You can start working on the tasks of exercise 1. You will see the project names of all your RStudio Projects listed in RStudio. Having the week number in the project name keeps you from getting confused on which project you are working on. "],["W1_5_tasks_and_inputs.html", "Tasks and inputs", " Tasks and inputs Before starting with the task: make sure you have read and followed the instructions in section Preparation In RStudio, open the RStudio Project you created for this week. You can see that you are in an RStudio Project if the projects name is visible next to the little RStudio logo in the top right corner of RStudio (otherwise it will read Project: (None)). Download the wildboar movement data here: wildschwein_BE.csv (right click Save target as..) Once you have set everything up, commit your file to your git repo in the following manner: Save your (R/RMarkdown) file Switch to the Git-Tab in the pane in the top right corner Click commit to open the commit-Window Click in the checkbox next to the file(s) you want to commit Add a commit message to explain what you are committing (e.g. initial commit) Click on commit to commit your changes Task 1: Import data Create a new R- (or RMarkdown) file and begin by loading the following packages: library(readr) # to import tabular data (e.g. csv) library(dplyr) # to manipulate (tabular) data library(ggplot2) # to visualize data Move the file wildschwein_BE.csv into your project directory and import it into r as a data.frame. Assign correct column types as necessary and make sure the time zone is set correctly for the date/time column. Note: We recommend using the readr package to import your data (they all begin with read_*, note the underscore). These functions are less error prone than the base R functions (read.*, note the period). Specifically for the wild boar data, we recommend read_delim(). Commit your changes as described in the beginning. Write a meaningful commit message (e.g. completed task 1). Task 2: Explore Data We will use a range of different visualization tools (i.e. R-packages) in this course. Several packages techniques have emerged in recent years, each with their specific strengths and weaknesses. While base::plot()is quick and simple, it not very scalable with growing complexity. ggplot2 offers solutions for most use cases and has an elegant, consistent syntax that is easy to get accustomed to. We will get to know other techniques later in the course. Get an overview of your data by creating a first map-like plot of your data producing a simple scatter plot with ggplot2. Setting up a ggplot with our data is done using the command ggplot(wildschwein_BE, aes(Long, Lat, colour = TierID)). Creating a map is done via the basic scatter plot command geom_point(). Assigning every individual its own colour is done using the ggplot argument colour =. Commit your changes as described in the beginning. Have a look at your commit history by clicking on History in the Git-Pane. Figure 1: Your plot should look something like this. Input: Handling spatial data Until now, weve stored our location data within data frames as Lat/Long columns. This works well for many tasks, but sometimes we need special spatial classes to handle our trajectories. We will get to know such cases in our next tasks, but first we need to convert our data.frame into a spatial object. We will largely rely on sfwhen working with vector data in R. In order to transform our data.frame into an sf object, we need to use the function st_as_sf() while specifying the columns storing the coordinates and the coordinate reference system. (At this point, we assume you know what a Coordinate Reference Systems is. Check out this link if this is not the case.) library(sf) wildschwein_BE_sf &lt;- st_as_sf(wildschwein_BE, coords = c(&quot;Long&quot;, &quot;Lat&quot;), crs = 4326) Notice how st_as_sf takes the EPSG code for the crs = argument. You can find a lot of useful information on Coordinate Reference Systems (including EPSG Codes, etc.) under epsg.io. Lets compare our original data.frame with this new sf object: wildschwein_BE ## # A tibble: 51,246 x 6 ## TierID TierName CollarID DatetimeUTC Lat Long ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 002A Sabi 12275 2014-08-22 21:00:12 47.0 7.05 ## 2 002A Sabi 12275 2014-08-22 21:15:16 47.0 7.05 ## 3 002A Sabi 12275 2014-08-22 21:30:43 47.0 7.05 ## 4 002A Sabi 12275 2014-08-22 21:46:07 47.0 7.05 ## 5 002A Sabi 12275 2014-08-22 22:00:22 47.0 7.05 ## 6 002A Sabi 12275 2014-08-22 22:15:10 47.0 7.05 ## 7 002A Sabi 12275 2014-08-22 22:30:13 47.0 7.05 ## 8 002A Sabi 12275 2014-08-22 22:45:11 47.0 7.05 ## 9 002A Sabi 12275 2014-08-22 23:00:27 47.0 7.05 ## 10 002A Sabi 12275 2014-08-22 23:15:41 47.0 7.05 ## # ... with 51,236 more rows wildschwein_BE_sf ## Simple feature collection with 51246 features and 4 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 7.019889 ymin: 46.97125 xmax: 7.112075 ymax: 47.01882 ## Geodetic CRS: WGS 84 ## # A tibble: 51,246 x 5 ## TierID TierName CollarID DatetimeUTC geometry ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;POINT [°]&gt; ## 1 002A Sabi 12275 2014-08-22 21:00:12 (7.049618 46.99317) ## 2 002A Sabi 12275 2014-08-22 21:15:16 (7.049509 46.99416) ## 3 002A Sabi 12275 2014-08-22 21:30:43 (7.049406 46.99383) ## 4 002A Sabi 12275 2014-08-22 21:46:07 (7.049217 46.99375) ## 5 002A Sabi 12275 2014-08-22 22:00:22 (7.049359 46.99375) ## 6 002A Sabi 12275 2014-08-22 22:15:10 (7.049363 46.99382) ## 7 002A Sabi 12275 2014-08-22 22:30:13 (7.049326 46.99387) ## 8 002A Sabi 12275 2014-08-22 22:45:11 (7.049237 46.99395) ## 9 002A Sabi 12275 2014-08-22 23:00:27 (7.048383 46.99481) ## 10 002A Sabi 12275 2014-08-22 23:15:41 (7.049396 46.99373) ## # ... with 51,236 more rows As you can see, st_as_sf() has added some metadata to our dataframe (geometry type, dimension, bbox, epsg and proj4string) and replaced the columns Lat and Long with a column named geometry. Other than that, the new sf object is very similar to our original dataframe. In fact, sf objects are essentially dataframes, as you can verify with the function is.data.frame(): is.data.frame(wildschwein_BE_sf) ## [1] TRUE All operations we know from handling data.frames can be used on the sf object. Try some out! # subset rows wildschwein_BE_sf[1:10,] wildschwein_BE_sf[wildschwein_BE_sf$TierName == &quot;Sabi&quot;,] # subset colums wildschwein_BE_sf[,2:3] Instead of keeping the same data twice (once as a data.frame, and once as an sf object), we will overwrite the data.frame and continue working with the sf object from now on. This saves some memory space in R and avoids confusion. wildschwein_BE &lt;- st_as_sf(wildschwein_BE, coords = c(&quot;Long&quot;, &quot;Lat&quot;), crs = 4326) rm(wildschwein_BE_sf) # we can remove this sf object, since it just eats up our memory Task 3: Project data from WGS84 So what can we do with our new sf object that we couldnt before? One example is projecting the WGS84 (Lat/Long) coordinates into the new Swiss CRS CH1903+ LV954. Do this by using the function st_transform. By the way, do you notice a pattern here? The package sf names most functions for spatial operations with the prefix st_*, just as in PostGIS. Heres the resulting sf object from the operation: wildschwein_BE ## Simple feature collection with 51246 features and 4 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 2568153 ymin: 1202306 xmax: 2575154 ymax: 1207609 ## Projected CRS: CH1903+ / LV95 ## # A tibble: 51,246 x 5 ## TierID TierName CollarID DatetimeUTC geometry ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;POINT [m]&gt; ## 1 002A Sabi 12275 2014-08-22 21:00:12 (2570409 1204752) ## 2 002A Sabi 12275 2014-08-22 21:15:16 (2570402 1204863) ## 3 002A Sabi 12275 2014-08-22 21:30:43 (2570394 1204826) ## 4 002A Sabi 12275 2014-08-22 21:46:07 (2570379 1204817) ## 5 002A Sabi 12275 2014-08-22 22:00:22 (2570390 1204818) ## 6 002A Sabi 12275 2014-08-22 22:15:10 (2570390 1204825) ## 7 002A Sabi 12275 2014-08-22 22:30:13 (2570387 1204831) ## 8 002A Sabi 12275 2014-08-22 22:45:11 (2570381 1204840) ## 9 002A Sabi 12275 2014-08-22 23:00:27 (2570316 1204935) ## 10 002A Sabi 12275 2014-08-22 23:15:41 (2570393 1204815) ## # ... with 51,236 more rows Commit your changes as described in the beginning. Input: Calculate Convex Hull Transforming from one Coordinate Reference System to another was one operation where we needed an object with a spatial nature. In this way, we were able to use an off the shelf function to project the coordinates from one CRS to another. In our next example, we again rely on a spatial function: We want to calculate a convex hull per Wild boar. And guess what the function for calculating a convex hull is called in sf? If you guessed st_convex_hull(), you were right! By default st_convex_hull() calculates the convex hull per feature, i.e. per point in our dataset. This of course makes little sense. In order to calculate the convex hull per animal, we need to convert our point- to multipoint-features where each feature contains all positions of one animal. This is achieved in two steps: First: add a grouping variable to the sf object. Note the new grouping variable in the metadata of the sf object. Other than that, group_by has no effect on our sf object. wildschwein_BE_grouped &lt;- group_by(wildschwein_BE,TierID) wildschwein_BE_grouped ## Simple feature collection with 51246 features and 4 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 2568153 ymin: 1202306 xmax: 2575154 ymax: 1207609 ## Projected CRS: CH1903+ / LV95 ## # A tibble: 51,246 x 5 ## # Groups: TierID [3] ## TierID TierName CollarID DatetimeUTC geometry ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;POINT [m]&gt; ## 1 002A Sabi 12275 2014-08-22 21:00:12 (2570409 1204752) ## 2 002A Sabi 12275 2014-08-22 21:15:16 (2570402 1204863) ## 3 002A Sabi 12275 2014-08-22 21:30:43 (2570394 1204826) ## 4 002A Sabi 12275 2014-08-22 21:46:07 (2570379 1204817) ## 5 002A Sabi 12275 2014-08-22 22:00:22 (2570390 1204818) ## 6 002A Sabi 12275 2014-08-22 22:15:10 (2570390 1204825) ## 7 002A Sabi 12275 2014-08-22 22:30:13 (2570387 1204831) ## 8 002A Sabi 12275 2014-08-22 22:45:11 (2570381 1204840) ## 9 002A Sabi 12275 2014-08-22 23:00:27 (2570316 1204935) ## 10 002A Sabi 12275 2014-08-22 23:15:41 (2570393 1204815) ## # ... with 51,236 more rows Second: use summarise() to dissolve all points into a mulipoint object. wildschwein_BE_smry &lt;- summarise(wildschwein_BE_grouped) wildschwein_BE_smry ## Simple feature collection with 3 features and 1 field ## Geometry type: MULTIPOINT ## Dimension: XY ## Bounding box: xmin: 2568153 ymin: 1202306 xmax: 2575154 ymax: 1207609 ## Projected CRS: CH1903+ / LV95 ## # A tibble: 3 x 2 ## TierID geometry ## &lt;chr&gt; &lt;MULTIPOINT [m]&gt; ## 1 002A ((2568903 1206200), (2568925 1206207), (2568980 1206197), (2569024 120~ ## 2 016A ((2569231 1205823), (2569245 1205925), (2569247 1206027), (2569251 120~ ## 3 018A ((2568153 1205611), (2568155 1205613), (2568161 1205624), (2568162 120~ Now we can run st_convex_hull on the new sf object. mcp &lt;- st_convex_hull(wildschwein_BE_smry) Task 4: Ploting spatial objects Using base plot to visualize sf objects is easy enough, just try the following code. plot(mcp) But since we use ggplot extensively, try and plot the object mcp with ggplot. Hint: Use the layer geom_sf() to add an sf object. Note: ggplot refuses to use our specified CRS, so we need to force this by specifying datum = in coord_sf(). Try it out. Commit your changes as described in the beginning. Have a look at your commit history by clicking on History in the Git-Pane. Input: Importing raster data In the next task, we would like to add a background map to our mcp object. Download the file here: pk100_BE.tif To import the file into R, we use the package terra with the function rast. library(terra) pk100_BE &lt;- terra::rast(&quot;00_Rawdata/pk100_BE.tif&quot;) pk100_BE ## class : SpatRaster ## dimensions : 1821, 2321, 3 (nrow, ncol, nlyr) ## resolution : 5, 5 (x, y) ## extent : 2567000, 2578605, 1199996, 1209101 (xmin, xmax, ymin, ymax) ## coord. ref. : CH1903+ / LV95 (EPSG:2056) ## source : pk100_BE.tif ## names : pk1_1, pk1_2, pk1_3 ## min values : 0, 0, 0 ## max values : 255, 255, 255 pk100_BE_2056.tif is a three layered geotiff File. The above console output shows some metadata including the resolution, extent and the names of our layers (pk1_1, pk1_2etc). With the default plot method, each layer is displayed individually: plot(pk100_BE) With plotRGB all three layers are combined into a single image: plotRGB(pk100_BE) Task 5: Adding a background map There are multiple ways to add a background map in ggplot, many require additional packages. This is a good opportunity to get to know a completely different package for creating maps: tmap (thematic map). This package was developed with a syntax very similar to ggplot2, which makes it easy to learn. library(tmap) tm_shape(pk100_BE) + tm_rgb() As you can see, plotting layers in tmap is combined with the + sign, just as in ggplot2. In tmap however, each layer consists of two objects: a tm_shape() in which the data is called, and a tm_* object in which we define how the data is visualized (tm_rgb() states that it is plotted as an RGB Raster Layer). Add the object mcp to the plot in this manner. Read the vignette if you are having trouble. Commit your changes as described in the beginning. Remember to add a meaningful commit message (e.g. completed task 5). Task 6: Create an interactive map Rerun the tmap()... command from the previous task, but switch the plotting mode to view\" (tmap_mode(\"view\")) beforehand. Omit the raster layer (pk100_BE), you wont be needing it. Commit your changes as described in the beginning. Have a look at your commit history by clicking on History in the Git-Pane. As weve mentioned in the first Input, you can look up the EPSG codes under http://epsg.io. For information specific to Switzerland, check the swisstopo website "],["W1_6_solutions.html", "Solutions", " Solutions Hover over the code and copy the content by clicking on the clipboard icon on the top right. You can now paste this into an R-Script. # task 1 ######################################################################## # Data import #### wildschwein_BE &lt;- read_delim(&quot;00_Rawdata/wildschwein_BE.csv&quot;,&quot;,&quot;) # Check Timezone attr(wildschwein_BE$DatetimeUTC,&quot;tzone&quot;) # or wildschwein_BE$DatetimeUTC[1] # task 2 ######################################################################## ggplot(wildschwein_BE, aes(Long,Lat, colour = TierID)) + geom_point() + theme(legend.position = &quot;none&quot;) # task 3 ######################################################################## wildschwein_BE &lt;- st_transform(wildschwein_BE, 2056) # task 4 ######################################################################## ggplot(mcp,aes(fill = TierID)) + geom_sf(alpha = 0.4) ggplot(mcp,aes(fill = TierID)) + geom_sf(alpha = 0.4) + coord_sf(datum = 2056) # task 5 ######################################################################## library(tmap) tm_shape(pk100_BE) + tm_rgb() tm_shape(pk100_BE) + tm_rgb() + tm_shape(mcp) + tm_polygons(col = &quot;TierID&quot;,alpha = 0.4,border.col = &quot;red&quot;) + tm_legend(bg.color = &quot;white&quot;) # task 6 ######################################################################## tmap_mode(&quot;view&quot;) tm_shape(mcp) + tm_polygons(col = &quot;TierID&quot;,alpha = 0.4,border.col = &quot;red&quot;) + tm_legend(bg.color = &quot;white&quot;) "],["W2_1_exercise.html", "Exercise 2", " Exercise 2 Learning Outcomes* You understand the dplyr functions mutate, summarise and group_by and can apply them to sf objects You can derive movement parameters (timelag, steplength, speed) from trajectory data. You can re-sample your trajectory data for cross-scale movement analysis. "],["W2_4_demo_tidyverse.html", "Demo Tidyverse", " Demo Tidyverse Download the code as an Rmd-File Depending on your knowledge of R, getting an overview of the data we imported last week might have been quite a challenge. Surprisingly enough, importing, cleaning and exploring your data can be the most challenging, time consuming part of a project. RStudio and the tidyverse offer many helpful tools to make this part easier (and more fun). You have read chapters on dplyr and magrittr as a preparation for this exercise. Before we start with the exercise however, this demo illustrates a simple approach offered by tidyverse which is applicable to sf-objects. Assume we want to calculate the timelag between subsequent positions. To achieve this we can use the function difftime() combined with lead() from dplyr. Lets look at these functions one by one. difftime difftime takes two POSIXct values. now &lt;- Sys.time() later &lt;- now + 10000 later ## [1] &quot;2022-06-01 17:01:56 CEST&quot; time_difference &lt;- difftime(later,now) time_difference ## Time difference of 2.777778 hours time_difference ## Time difference of 2.777778 hours You can also specify the unit of the output. time_difference &lt;- difftime(later,now,units = &quot;mins&quot;) time_difference ## Time difference of 166.6667 mins difftime returns an object of the Class difftime. However in our case, numeric values would be more handy than the Class difftime. So well wrap the command in as.numeric(): class(time_difference) ## [1] &quot;difftime&quot; str(time_difference) ## &#39;difftime&#39; num 166.666666666667 ## - attr(*, &quot;units&quot;)= chr &quot;mins&quot; time_difference &lt;- as.numeric(difftime(later,now,units = &quot;mins&quot;)) str(time_difference) ## num 167 class(time_difference) ## [1] &quot;numeric&quot; lead() / lag() lead() and lag() return a vector of the same length as the input, just offset by a specific number of values (default is 1). Consider the following sequence: numbers &lt;- 1:10 numbers ## [1] 1 2 3 4 5 6 7 8 9 10 We can now run lead() and lag() on this sequence to illustrate the output. n = specifies the offset, default = specifies the default value used to fill the emerging empty spaces of the vector. This helps us performing operations on subsequent values in a vector (or rows in a table). library(dplyr) ## ## Attache Paket: &#39;dplyr&#39; ## Die folgenden Objekte sind maskiert von &#39;package:stats&#39;: ## ## filter, lag ## Die folgenden Objekte sind maskiert von &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union lead(numbers) ## [1] 2 3 4 5 6 7 8 9 10 NA lead(numbers,n = 2) ## [1] 3 4 5 6 7 8 9 10 NA NA lag(numbers) ## [1] NA 1 2 3 4 5 6 7 8 9 lag(numbers,n = 5) ## [1] NA NA NA NA NA 1 2 3 4 5 lag(numbers,n = 5, default = 0) ## [1] 0 0 0 0 0 1 2 3 4 5 mutate() Using the above functions (difftime() and lead()), we can calculate the time lag, that is, the time difference between consecutive positions. We will try this on a dummy version of our wildboar dataset. wildschwein &lt;- tibble( TierID = c(rep(&quot;Hans&quot;,5),rep(&quot;Klara&quot;,5)), DatetimeUTC = rep(as.POSIXct(&quot;2015-01-01 00:00:00&quot;,tz = &quot;UTC&quot;)+0:4*15*60, 2) ) wildschwein ## # A tibble: 10 x 2 ## TierID DatetimeUTC ## &lt;chr&gt; &lt;dttm&gt; ## 1 Hans 2015-01-01 00:00:00 ## 2 Hans 2015-01-01 00:15:00 ## 3 Hans 2015-01-01 00:30:00 ## 4 Hans 2015-01-01 00:45:00 ## 5 Hans 2015-01-01 01:00:00 ## 6 Klara 2015-01-01 00:00:00 ## 7 Klara 2015-01-01 00:15:00 ## 8 Klara 2015-01-01 00:30:00 ## 9 Klara 2015-01-01 00:45:00 ## 10 Klara 2015-01-01 01:00:00 To calculate the timelag with base-R, we need to mention wildschwein three times wildschwein$timelag &lt;- as.numeric(difftime(lead(wildschwein$DatetimeUTC), wildschwein$DatetimeUTC)) Using mutate() we can simplify this operation slightly: wildschwein &lt;- mutate(wildschwein,timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC))) wildschwein ## # A tibble: 10 x 3 ## TierID DatetimeUTC timelag ## &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 Hans 2015-01-01 00:00:00 15 ## 2 Hans 2015-01-01 00:15:00 15 ## 3 Hans 2015-01-01 00:30:00 15 ## 4 Hans 2015-01-01 00:45:00 15 ## 5 Hans 2015-01-01 01:00:00 -60 ## 6 Klara 2015-01-01 00:00:00 15 ## 7 Klara 2015-01-01 00:15:00 15 ## 8 Klara 2015-01-01 00:30:00 15 ## 9 Klara 2015-01-01 00:45:00 15 ## 10 Klara 2015-01-01 01:00:00 NA group_by() You might have noticed that timelag is calculated across different individuals (Hans and Klara), which does not make much sense. To avoid this, we need to specify that timelag should just be calculated between consecutive rows of the same individual. We can implement this by using group_by(). wildschwein &lt;- group_by(wildschwein,TierID) After adding this grouping variable, calculating the timelag automatically accounts for the individual trajectories. wildschwein &lt;- mutate(wildschwein,timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC))) wildschwein ## # A tibble: 10 x 3 ## # Groups: TierID [2] ## TierID DatetimeUTC timelag ## &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 Hans 2015-01-01 00:00:00 15 ## 2 Hans 2015-01-01 00:15:00 15 ## 3 Hans 2015-01-01 00:30:00 15 ## 4 Hans 2015-01-01 00:45:00 15 ## 5 Hans 2015-01-01 01:00:00 NA ## 6 Klara 2015-01-01 00:00:00 15 ## 7 Klara 2015-01-01 00:15:00 15 ## 8 Klara 2015-01-01 00:30:00 15 ## 9 Klara 2015-01-01 00:45:00 15 ## 10 Klara 2015-01-01 01:00:00 NA summarise() If we want to summarise our data and get metrics per animal, we can use the dplyr function summarise(). In contrast to mutate(), which just adds a new column to the dataset, summarise() collapses the data to one row per individual (specified by group_by). summarise(wildschwein, mean = mean(timelag, na.rm = T)) ## # A tibble: 2 x 2 ## TierID mean ## &lt;chr&gt; &lt;dbl&gt; ## 1 Hans 15 ## 2 Klara 15 Note: You can do mutate() and summarise() on sf objects as well. However, summarise() tries to coerce all geometries into one object, which can take along time. To avoid this, use st_drop_geometry() before using summarise(). Piping The code above may be a bit hard to read, since it has so many nested functions which need to be read from the inside out. In order to make code readable in a more human-friendly way, we can use the piping command %&gt;% from magrittr, which is included in dplyr and the tidyverse. The above code then looks like this: wildschwein %&gt;% # Take wildschwein... group_by(TierID) %&gt;% # ...group it by TierID summarise( # Summarise the data... mean_timelag = mean(timelag,na.rm = T)# ...by calculating the mean timelag ) ## # A tibble: 2 x 2 ## TierID mean_timelag ## &lt;chr&gt; &lt;dbl&gt; ## 1 Hans 15 ## 2 Klara 15 Bring it all together Here is the same approach with a different dataset: pigs &lt;- tibble( TierID = c(8001,8003,8004,8005,8800,8820,3000,3001,3002,3003,8330,7222), sex = c(&quot;M&quot;,&quot;M&quot;,&quot;M&quot;,&quot;F&quot;,&quot;M&quot;,&quot;M&quot;,&quot;F&quot;,&quot;F&quot;,&quot;M&quot;,&quot;F&quot;,&quot;M&quot;,&quot;F&quot;), age= c (&quot;A&quot;,&quot;A&quot;,&quot;J&quot;,&quot;A&quot;,&quot;J&quot;,&quot;J&quot;,&quot;J&quot;,&quot;A&quot;,&quot;J&quot;,&quot;J&quot;,&quot;A&quot;,&quot;A&quot;), weight = c(50.755,43.409,12.000,16.787,20.987,25.765,22.0122,21.343,12.532,54.32,11.027,88.08) ) pigs ## # A tibble: 12 x 4 ## TierID sex age weight ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 8001 M A 50.8 ## 2 8003 M A 43.4 ## 3 8004 M J 12 ## 4 8005 F A 16.8 ## 5 8800 M J 21.0 ## 6 8820 M J 25.8 ## 7 3000 F J 22.0 ## 8 3001 F A 21.3 ## 9 3002 M J 12.5 ## 10 3003 F J 54.3 ## 11 8330 M A 11.0 ## 12 7222 F A 88.1 pigs %&gt;% summarise( mean_weight = mean(weight) ) ## # A tibble: 1 x 1 ## mean_weight ## &lt;dbl&gt; ## 1 31.6 pigs %&gt;% group_by(sex) %&gt;% summarise( mean_weight = mean(weight) ) ## # A tibble: 2 x 2 ## sex mean_weight ## &lt;chr&gt; &lt;dbl&gt; ## 1 F 40.5 ## 2 M 25.2 pigs %&gt;% group_by(sex,age) %&gt;% summarise( mean_weight = mean(weight) ) ## `summarise()` has grouped output by &#39;sex&#39;. You can override using the `.groups` argument. ## # A tibble: 4 x 3 ## # Groups: sex [2] ## sex age mean_weight ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 F A 42.1 ## 2 F J 38.2 ## 3 M A 35.1 ## 4 M J 17.8 "],["W2_4b_demo_tidyverse_code.html", "Demo Tidyverse (R-Code)", " Demo Tidyverse (R-Code) now &lt;- Sys.time() later &lt;- now + 10000 later time_difference &lt;- difftime(later,now) time_difference time_difference time_difference &lt;- difftime(later,now,units = &quot;mins&quot;) time_difference class(time_difference) str(time_difference) time_difference &lt;- as.numeric(difftime(later,now,units = &quot;mins&quot;)) str(time_difference) class(time_difference) numbers &lt;- 1:10 numbers library(dplyr) lead(numbers) lead(numbers,n = 2) lag(numbers) lag(numbers,n = 5) lag(numbers,n = 5, default = 0) wildschwein &lt;- tibble( TierID = c(rep(&quot;Hans&quot;,5),rep(&quot;Klara&quot;,5)), DatetimeUTC = rep(as.POSIXct(&quot;2015-01-01 00:00:00&quot;,tz = &quot;UTC&quot;)+0:4*15*60, 2) ) wildschwein wildschwein$timelag &lt;- as.numeric(difftime(lead(wildschwein$DatetimeUTC), wildschwein$DatetimeUTC)) wildschwein &lt;- mutate(wildschwein,timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC))) wildschwein wildschwein &lt;- group_by(wildschwein,TierID) wildschwein &lt;- mutate(wildschwein,timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC))) wildschwein summarise(wildschwein, mean = mean(timelag, na.rm = T)) wildschwein %&gt;% # Take wildschwein... group_by(TierID) %&gt;% # ...group it by TierID summarise( # Summarise the data... mean_timelag = mean(timelag,na.rm = T)# ...by calculating the mean timelag ) pigs &lt;- tibble( TierID = c(8001,8003,8004,8005,8800,8820,3000,3001,3002,3003,8330,7222), sex = c(&quot;M&quot;,&quot;M&quot;,&quot;M&quot;,&quot;F&quot;,&quot;M&quot;,&quot;M&quot;,&quot;F&quot;,&quot;F&quot;,&quot;M&quot;,&quot;F&quot;,&quot;M&quot;,&quot;F&quot;), age= c (&quot;A&quot;,&quot;A&quot;,&quot;J&quot;,&quot;A&quot;,&quot;J&quot;,&quot;J&quot;,&quot;J&quot;,&quot;A&quot;,&quot;J&quot;,&quot;J&quot;,&quot;A&quot;,&quot;A&quot;), weight = c(50.755,43.409,12.000,16.787,20.987,25.765,22.0122,21.343,12.532,54.32,11.027,88.08) ) pigs pigs %&gt;% summarise( mean_weight = mean(weight) ) pigs %&gt;% group_by(sex) %&gt;% summarise( mean_weight = mean(weight) ) pigs %&gt;% group_by(sex,age) %&gt;% summarise( mean_weight = mean(weight) ) "],["W2_3_preparation.html", "Preparation", " Preparation This week, we are going to further leverage Git by connecting it to an online repository. Git on its own can be useful, but to use all of the advantages its best to combine it with an hosted service like Github. Step 1: Create a Github account Typically, you do this once (in a lifetime) Last week, you worked with git on your local machine, with no way of synchronising your changes with a cloud server. This week you will use Github to sync your changes. To do this, create a Github account on github.com (its free of course). Use the email address that you configured in git last week. If you are not sure which mail you used, type git config user.email in the shell terminal. You dont have to use the same username on Github and in Git. When choosing a username on Github, consider the following advice: incorporating your actual name is nice, people like to know who they are dealing with choose a name that you are comfortable revealing it to a future boss shorter is better than longer make it timeless (e.g. dont incorporate your universitys name) Step 2: Authenticate Git to work with Github Typically, you do this once (per computer) If we want to push changes from our local repository to your Github cloud repository, Github must verify your credentials. Other software might just ask for your username and password, its a little different with Git. Basically there are two ways to connect with your remote repo (ssh and https), we will use https in this course. First, create a personal access token (PAT) on Github Login into github.com, click on your user profile (top right) and click on Settings Choose Developer settings &gt; Personal access tokens &gt; Generate new token Add a descriptive note (e.g. https access from my personal laptop) Select scope repo Click on Generate token Copy your new personal access token (in the green box) You wont be able to see this token again If you loose it, you can simply create a new one If you want to store it, you neeed to treat this Personal access tokens (PAT) like a password. Only store it in a secure place (like a password management app) and never publish this PAT publicly Then, store your PAT in you local Git In R, install the gitcreds package (install.packages(\"gitcreds\")) Load this library (library(gitcreds)) Call the function gitcreds_set() Respond to the prompt with your PAT from the last step Check that you have stored a credential with gitcreds_get() Step 3: Create a Github repo Typically, you do this once per project Now you can create a repository on Github that you can afterwards connect to your RStudio project from this week (which you will create in the next step). To do this, go to github.com and click on the plus sign in the top right corner, then fill in the following information: Repository name: Give a meaningful name, e.g. cma-week2 Description: Give a meaningful description, e.g. Solving exercise 2 of the course \"Computational Movement Analysis\" Make the repo public, not private Choose Add a README file Click on Create repository, then on the green button Code. Select HTTPS (it might already be selected) and then copy the URL by clicking on the clipboard symbol. The URL should look something list this https://github.com/YOUR-GITHUB-USERNAME/cma-week2.git. Report this URL back to us via Moodle (under L2 Data Issues &gt; R Exercises E2 &gt; Exercise 2 (Github URL)) Step 4: Create a new RStudio Project Typically, you do this once per project You will now create a new RStudio Project for week 2. Unlike last week, we will create the project in such a way that it is immediately connected to our Github repo. In RStudio, start a new project. Choose: File &gt; New Project &gt; Version Control &gt; Git. In the repository URL, paste the URL you copied in the last step Change Project directory name to week2-rexercise (if you are following the convention we proposed last week) Change the parent directory (Create project as a subdirectory of) to your equivalent of C:/Users/yourname/semester2/Modul_CMA/week2 Click on Create Project. You are now all set and can start with this weeks tasks! PS: You just created an RStudio Project which is automatically connected to Github. You can also connect existing local Git repositories (e.g. from week 1) to Github. You have the chance to learn this in Week 3. "],["W2_5_tasks_and_inputs.html", "Tasks and Inputs", " Tasks and Inputs Open the RStudio Project you created for week 2 in the preparation Download the new wildboar movement data, and save it to your new projects directory wildschwein_BE_2056.csv (right click Save target as..) Now, commit your changes to your repo like we did last week (see below): Save your (R/RMarkdown) file Switch to the Git-Tab in the pane in the top right corner Click commit to open the commit-Window Click in the checkbox next to the file(s) you want to commit Add a commit message to explain what you are committing (e.g. initial commit) Click on commit to commit your changes To push your changes from our local repo on your computer to the remote repo on Github, simply click the green button Push in the Git tab in RStudio. Now take a look at your repository on github.com. Do you see the new files there? Contact us if this does not work. Note: You do not need to push your changes to your remote repo after every commit. Its enough if you do this every few commits. Task 1: Import your data Create a new R- (or RMarkdown-) file and begin with the following lines of code (adjust the path to your csv file accordingly). ## Load the necessary libraries ################################################ library(readr) # to import tabular data (e.g. csv) library(dplyr) # to manipulate (tabular) data library(ggplot2) # to visualize data library(sf) # to handle spatial vector data library(terra) # To handle raster data library(lubridate) # To handle dates and times ## Import the downloaded csv ################################################## wildschwein_BE &lt;- read_delim(&quot;00_Rawdata/wildschwein_BE_2056.csv&quot;,&quot;,&quot;) # adjust path wildschwein_BE &lt;- st_as_sf(wildschwein_BE, coords = c(&quot;E&quot;, &quot;N&quot;), crs = 2056, remove = FALSE) Note: that this dataset is already converted to EPSG 2056 the coordinates are stored in the columns (E/N) setting remove = FALSE preserves the original (E/N) columns, which come in handy later on Task 2: Getting an overview Calculate the time difference between subsequent rows as described in the demo. You can calculate the time difference using the function difftime() in combination with lead(). the function difftime() has an option units. Set this to secs to get the time difference in seconds use as.integer() to turn the output returned by difftime() into an integer. store the output in a new column (e.g. timelag) Now inspect your data in more detail. Try to answer the following questions: How many individuals were tracked? For how long were the individual tracked? Are there gaps? Were all individuals tracked concurrently or sequentially? What is the temporal sampling interval between the locations? Here are some exemplary visualisation you could produce to answer these questions. Can you now answer the above questions? After completing the task, commit your changes to git using a good commit message (e.g. completed task 1). Task 3: Deriving movement parameters I: Speed In this task we will derive some additional movement parameters from our trajectories. So far our trajectories only consist of a list of time-stamped spatial locations. So lets calculate the animals steplength based on the Euclidean distance between two subsequent locations. You can calculate the Euclidean distance with the following formula: \\[\\text{distance} = \\sqrt{(\\text{E1} - \\text{E2})^{2}+(\\text{N1} - \\text{N2})^{2}}\\] E1, N1 refers to the current location E2, N2 refers to the consecutive location you can use lead(E,1) to address E2 store the output in a new column (e.g. steplength) Now calculate the animals speed between consecutive locations based on steplength and the timelag (from the last task). What speed unit do you get? After completing the task, commit your changes to git using a good commit message. Task 4: Cross-scale movement analysis Laube and Purves (2011) analyse animal movement across different scales (see below). In their paper, the authors suggest reducing the granularity of the data by subsetting the data to every nth element. We will do the same on a dataset that includes 200 locations of a single wild boar with a constant sampling interval of 60 seconds. Figure 2: Black points are used in calculation of movement parameters (e.g. speed) at a given termporal scale (Laube and Purves, 2011) Download this dataset here: caro60.csv (right click: save target as..). Import it just like you imported the other wild boar data and save it to a new variable named caro (note that the locations are stored in EPSG 2056). Now manually reduce the granularity of our sampling interval by selecting every 3rd, 6th and 9th position and save the output to caro_3, caro_6,caro_9 accordingly. Tip: There are many ways to go about this, we recommend using seq() where from = 1, to = the length of the dataset and by = n (i.e. 3, 6 or 9). This creates an integer vector that can either used in dplyr::slice() or in row subsetting (type ?slice() or ?\"[.data.frame\" to get help on either of these methods). You should now have 4 datasets with different number of rows: nrow(caro) ## [1] 200 nrow(caro_3) ## [1] 67 nrow(caro_6) ## [1] 34 nrow(caro_9) ## [1] 23 Now calculate timelag, steplength and speed for these data sets, just as you did in the last task. To finish the task, compare the speeds visually in a line plot and also visualize the trajectories in a map (see examples below). Interpret the line plot, what do the different lines for the different temporal granularities tell you? After completing the task, commit your changes to git using a good commit message. ## # A tibble: 67 x 6 ## TierID TierName CollarID DatetimeUTC E N ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 010C Caro 13973 2015-09-15 08:07:00 2570589. 1205095. ## 2 010C Caro 13973 2015-09-15 08:10:00 2570518. 1205115. ## 3 010C Caro 13973 2015-09-15 08:13:00 2570482. 1205124. ## 4 010C Caro 13973 2015-09-15 08:16:00 2570490. 1205100. ## 5 010C Caro 13973 2015-09-15 08:19:00 2570497. 1205092. ## 6 010C Caro 13973 2015-09-15 08:22:00 2570499. 1205091. ## 7 010C Caro 13973 2015-09-15 08:25:00 2570500. 1205087. ## 8 010C Caro 13973 2015-09-15 08:28:00 2570496. 1205094. ## 9 010C Caro 13973 2015-09-15 08:31:00 2570497. 1205091. ## 10 010C Caro 13973 2015-09-15 08:34:00 2570499. 1205091. ## # ... with 57 more rows Task 5: Deriving movement parameters II: Rolling window functions A different approach would be to smoothen the derived parameters using a moving window function. The zoo package offers a variate of moving window functions (roll_*). Install this package, load it into the session and use the function roll_mean() to smooth the calculated speed. Familiarise yourself with this function by working on some dummy data, for example: library(zoo) example &lt;- rnorm(10) rollmean(example,k = 3,fill = NA,align = &quot;left&quot;) ## [1] -0.5049544 -0.3781283 -0.1273157 0.4523153 0.4534811 0.8658536 ## [7] 0.5452571 1.0210648 NA NA rollmean(example,k = 4,fill = NA,align = &quot;left&quot;) ## [1] -0.25933381 -0.22379720 0.06456868 0.45949282 0.70918920 0.56899826 ## [7] 0.88605495 NA NA NA Now run rollmeanon the speed variable of the subset (caro). Visualize the output from your moving windows and compare different window sizes (k =). After completing the task, commit your changes to git using a good commit message. Additionally, push all your commits to your remote repository on Github by clicking the green upwards pointing arrow in the Git pane in RStudio. Submission To submit your exercise, provide us with the URL of your Github repo as described in the preperation. "],["W2_6_solutions.html", "Solutions", " Solutions Hover over the code and copy the content by clicking on the clipboard icon on the top right. You can now paste this into an R-Script. # task 0 ######################################################################## ## Load the necessary libraries ################################################ library(readr) # to import tabular data (e.g. csv) library(dplyr) # to manipulate (tabular) data library(ggplot2) # to visualize data library(sf) # to handle spatial vector data library(terra) # To handle raster data library(lubridate) # To handle dates and times ## Import the downloaded csv ################################################## wildschwein_BE &lt;- read_delim(&quot;00_Rawdata/wildschwein_BE_2056.csv&quot;,&quot;,&quot;) # adjust path wildschwein_BE &lt;- st_as_sf(wildschwein_BE, coords = c(&quot;E&quot;, &quot;N&quot;), crs = 2056, remove = FALSE) # task 1 ######################################################################## wildschwein_BE &lt;- wildschwein_BE %&gt;% mutate(timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = &quot;secs&quot;))) ggplot(wildschwein_BE, aes(DatetimeUTC,TierID)) + geom_line() ggplot(wildschwein_BE, aes(timelag)) + geom_histogram(binwidth = 50) + lims(x = c(0,15000)) + scale_y_log10() wildschwein_BE %&gt;% filter(year(DatetimeUTC) == 2014) %&gt;% ggplot(aes(DatetimeUTC,timelag, colour = TierID)) + geom_line() + geom_point() # task 2 ######################################################################## wildschwein_BE &lt;- wildschwein_BE %&gt;% group_by(TierID) %&gt;% mutate( steplength = sqrt((E-lead(E))^2+(N-lead(N))^2) ) wildschwein_BE &lt;- wildschwein_BE %&gt;% group_by(TierID) %&gt;% mutate( speed = steplength/timelag ) # task 3 ######################################################################## caro &lt;- read_delim(&quot;00_Rawdata/caro60.csv&quot;,&quot;,&quot;) caro[seq(1, nrow(caro),3), ] caro_3 &lt;- caro[seq(1, nrow(caro),3), ] caro_6 &lt;- caro[seq(1, nrow(caro),6), ] caro_9 &lt;- caro[seq(1, nrow(caro),9), ] caro &lt;- caro %&gt;% mutate( timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = &quot;secs&quot;)), steplength = sqrt((E-lead(E))^2+(N-lead(N))^2), speed = steplength/timelag ) caro_3 &lt;- caro_3 %&gt;% mutate( timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = &quot;secs&quot;)), steplength = sqrt((E-lead(E))^2+(N-lead(N))^2), speed = steplength/timelag ) caro_6 &lt;- caro_6 %&gt;% mutate( timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = &quot;secs&quot;)), steplength = sqrt((E-lead(E))^2+(N-lead(N))^2), speed = steplength/timelag ) caro_9 &lt;- caro_9 %&gt;% mutate( timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = &quot;secs&quot;)), steplength = sqrt((E-lead(E))^2+(N-lead(N))^2), speed = steplength/timelag ) ggplot() + geom_point(data = caro, aes(E,N, colour = &quot;1 minute&quot;), alpha = 0.2) + geom_path(data = caro, aes(E,N, colour = &quot;1 minute&quot;), alpha = 0.2) + geom_point(data = caro_3, aes(E,N, colour = &quot;3 minutes&quot;)) + geom_path(data = caro_3, aes(E,N, colour = &quot;3 minutes&quot;)) + labs(color=&quot;Trajectory&quot;, title = &quot;Comparing original- with 3 minutes-resampled data&quot;) + theme_minimal() ggplot() + geom_point(data = caro, aes(E,N, colour = &quot;1 minute&quot;), alpha = 0.2) + geom_path(data = caro, aes(E,N, colour = &quot;1 minute&quot;), alpha = 0.2) + geom_point(data = caro_6, aes(E,N, colour = &quot;6 minutes&quot;)) + geom_path(data = caro_6, aes(E,N, colour = &quot;6 minutes&quot;)) + labs(color=&quot;Trajectory&quot;, title = &quot;Comparing original- with 6 minutes-resampled data&quot;) + theme_minimal() ggplot() + geom_point(data = caro, aes(E,N, colour = &quot;1 minute&quot;), alpha = 0.2) + geom_path(data = caro, aes(E,N, colour = &quot;1 minute&quot;), alpha = 0.2) + geom_point(data = caro_9, aes(E,N, colour = &quot;9 minutes&quot;)) + geom_path(data = caro_9, aes(E,N, colour = &quot;9 minutes&quot;))+ labs(color=&quot;Trajectory&quot;, title = &quot;Comparing original- with 9 minutes-resampled data&quot;) + theme_minimal() ggplot() + geom_line(data = caro, aes(DatetimeUTC,speed, colour = &quot;1 minute&quot;)) + geom_line(data = caro_3, aes(DatetimeUTC,speed, colour = &quot;3 minutes&quot;)) + geom_line(data = caro_6, aes(DatetimeUTC,speed, colour = &quot;6 minutes&quot;)) + geom_line(data = caro_9, aes(DatetimeUTC,speed, colour = &quot;9 minutes&quot;)) + labs(x = &quot;Time&quot;,y = &quot;Speed (m/s)&quot;, title = &quot;Comparing derived speed at different sampling intervals&quot;) + theme_minimal() # task 4 ######################################################################## library(zoo) example &lt;- rnorm(10) rollmean(example,k = 3,fill = NA,align = &quot;left&quot;) rollmean(example,k = 4,fill = NA,align = &quot;left&quot;) caro &lt;- caro %&gt;% mutate( speed3 = rollmean(speed,3,NA,align = &quot;left&quot;), speed6 = rollmean(speed,6,NA,align = &quot;left&quot;), speed9 = rollmean(speed,9,NA,align = &quot;left&quot;) ) caro %&gt;% ggplot() + geom_line(aes(DatetimeUTC,speed), colour = &quot;#E41A1C&quot;) + geom_line(aes(DatetimeUTC,speed3), colour = &quot;#377EB8&quot;) + geom_line(aes(DatetimeUTC,speed6), colour = &quot;#4DAF4A&quot;) + geom_line(aes(DatetimeUTC,speed9), colour = &quot;#984EA3&quot;) "],["W3_1_exercise.html", "Exercise 3", " Exercise 3 Learning Outcomes* You are able to segment a trajectory, e.g. using the approach proposed in Laube and Purves (2011) You are able to compute the similarity between given trajectories using the package SimilarityMeasures. You acquire further useful data processing skills. "],["W3_3_preparation.html", "Preparation", " Preparation We need to create a new RStudio Project with Git and Github this week. Last week you created an RStudio Project which was automatically connected to Github. You did this by first creating a Github Repo, and then initiating the RStudio Project via File &gt; New Project &gt; Version Control &gt; Git (adding the URL of your Github Repo). This is definitely the easiest way to set up a connection, but what if you have an existing project that you want to connect to Github? In this next section, we will go through setting up Git and Github without the use of RStudio. It will take slightly longer than the setup we used last week. Also, you will be confronted with some additional jargon. As additional ressources to learning Git, we highly recommend: The video tutorials by Corey Schafer or the very entertaining learning series Git and Github for Poets. Happy Git with Github for the useR is an excellent, easy to read, openly available book, written specifically for students working with R and RStudio in data science and related fields Step 1: Create a normal RStudio Project Create a new RStudio Project File &gt; New Project &gt; New Directory &gt; New Project. This will create a normal RStudio Project without Git version control (and consequently without a Github connection). This is a typical situation for a project that you started without version control in mind. Choose the following settings: Directory name: Choose a directory name that suits your structure Create project as a subdirectory of: Choose a parent directory that suits your folder structure Create a git repository: not checked (we will do this manually in the next step) Use renv with this project: not checked Step 2: Activate Git Version Control Activating Git Version Control for your project is one line of code. In your shell terminal, type the following command (which is what RStudio effectively does automatically when you activate the Create a git repository option while creating your project): git init You should get a message, saying Initialized empty Git repository in C:/path/to/your/directory/.git/. You will see this folder (named .git) in your projects root directory (check your Files pane ). If you dont see it there, click Refresh file listing (refresh symbol to the very right of the files pane). If you still dont see it, make hidden files visible (Files pane &gt; More &gt; Show hidden files) To see the Git Pane in RStudio, reload RStudio either by restarting it or clicking on the name of your RStudio project in the top right corner of RStudio and selecting your project from the project list). Step 3: Rename branch In your Git pane, you will see that you do not have a branch yet, it says (no branch) in the top right corner. But what is branch? Branches are a way to have multiple versions of your project, which is especially useful if you want to do experiments that you are unsure about. We will not cover branches in this course, but its important that you have heard of the term, since its considered to be Gits Killer feature. Once you make your first commit, Git will automatically create a branch named master. Test this by committing the.gitignore and ...*.Rproj-File. master is just a convention for the main (and maybe only) version of your project. Since 2020, there are efforts to avoid offensive jargon in tech, including the term master. In this effort, Github has switched to using main as the name for the main branch, while Git still uses master. We can rename our master branch to main with the following line of code (note that you must have committed something first): git branch -M main Step 4: Create a Github Repository Now create a Github Repository following the instructions from last week. This time however, dont check Add a README file. Copy the https URL to your Github repo, which should look something like this: https://github.com/YOUR-GITHUB-USERNAME/cma-week3.git Report the URL of your new repo back to us via Moodle! Step 5: Connect to Github To connect your (local) RStudio Project to Github, we have to set up our Github repo to be our so called remote repository. We could have multiple remotes, which is why we need to name it, and the convention is to call it origin. To create a remote named origin, type the following command in your shell terminal: git remote add origin https://github.com/YOUR-GITHUB-USERNAME/cma-week3.git The first time we push to this remote repository, we need to specify the an upstream, so that future git push will be directed to the correct remote branch. We can to this with the --set-upstream (or -u) git push --set-upstream origin main This command prints a couple of messages, ending with the following statement: Branch 'main' set up to track remote branch 'main' from 'origin'.. Now that the upstream (i.e.) tracking branch is correctly set up, you can also push via the Git pane in RStudio (you might need to refresh the Git pane first). "],["W3_4_tasks_and_inputs.html", "Tasks and Inputs", " Tasks and Inputs Youve read Laube and Purves (2011) about segmenting trajectories. In the paper, the authors define static fixes as those whose average Euclidean distance to other fixes inside a temporal window v is less than some threshold d, as illustrated in the following figure: Figure 3: The figure from Laube and Purves (2011) visualizes steps a) zu d), which will be explained below: Specify a temporal windows \\(v\\) for in which to measure Euclidean distances Measure the distance from every point to every other point within this temporal window (\\(v\\)) Remove static points: These are points where the average distance is less than a given threshold. This segments the trajectory into subtrajectories Now remove short subtrajectories: These are trajectories with a short duration (whereas short is tbd) We will demonstrate implementing this method on the wild boar Sabi, restricting ourselves to a couple of tracking days. Your task will be to understand this implementation and apply it on Caro, with a different sampling interval. Figure 4: Movement of the wildboar Sabi in the timespan 01-02.07.2015. The circle highlingts possible static points Step a): Specify a temporal window \\(v\\) In the above dataset, the sampling interval is 15 minutes. If we take a temporal window of 60 minutes, that would mean including 4 fixes. We need to calculate the following Euclidean distances (pos representing single location): pos[n-2] to pos[n] pos[n-1] to pos[n] pos[n] to pos[n+1] pos[n] to pos[n+2] Step b): Measure the distance from every point to every other point within this temporal window \\(v\\) Just like last week, we use the formula for calculating the Euclidean distance in in combination with lead() and lag(). For example, to create the necessary offset of n-2, we use lag(x, 2). For each offset, we create one individual column. sabi &lt;- sabi %&gt;% mutate( nMinus2 = sqrt((lag(E,2)-E)^2+(lag(N,2)-N)^2), # distance to pos -30 minutes nMinus1 = sqrt((lag(E,1)-E)^2+(lag(N,1)-N)^2), # distance to pos -15 minutes nPlus1 = sqrt((E-lead(E,1))^2+(N-lead(N,1))^2), # distance to pos +15 mintues nPlus2 = sqrt((E-lead(E,2))^2+(N-lead(N,2))^2) # distance to pos +30 minutes ) Now we want to calculate the mean distance of nMinus2, nMinus1, nPlus1, nPlus2 for each row. Since we want the mean value per Row, we have to explicitly specify this before mutate() with the function rowwise(). To remove this rowwise-grouping, we end the operation with ungroup(). Note that for the first two positions, we cannot calculate a stepMean since there is no Position n-2 for these positions. This is also true for the last to positions (lacking a position n+2). sabi &lt;- sabi %&gt;% rowwise() %&gt;% mutate( stepMean = mean(c(nMinus2, nMinus1,nPlus1,nPlus2)) ) %&gt;% ungroup() sabi ## # A tibble: 192 x 11 ## TierID TierName CollarID DatetimeUTC E N nMinus2 nMinus1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 002A Sabi 12275 2015-06-30 22:00:13 2569972. 1.21e6 NA NA ## 2 002A Sabi 12275 2015-06-30 22:16:06 2569975. 1.21e6 NA 271. ## 3 002A Sabi 12275 2015-06-30 22:30:19 2570266. 1.21e6 573. 365. ## 4 002A Sabi 12275 2015-06-30 22:45:13 2570208. 1.21e6 361. 80.5 ## 5 002A Sabi 12275 2015-06-30 23:00:10 2570247. 1.21e6 127. 186. ## 6 002A Sabi 12275 2015-06-30 23:15:17 2570512. 1.21e6 703. 524. ## 7 002A Sabi 12275 2015-06-30 23:30:38 2570684. 1.21e6 766. 247. ## 8 002A Sabi 12275 2015-06-30 23:45:16 2570526. 1.21e6 229. 167. ## 9 002A Sabi 12275 2015-07-01 00:00:10 2570532. 1.21e6 163. 9.33 ## 10 002A Sabi 12275 2015-07-01 00:15:14 2570530. 1.21e6 8.98 15.4 ## # ... with 182 more rows, and 3 more variables: nPlus1 &lt;dbl&gt;, nPlus2 &lt;dbl&gt;, ## # stepMean &lt;dbl&gt; Step c): Remove static points We can now determine if an animal is moving or not by specifying a threshold distance on stepMean. In our example, we use the mean value as a threshold: Positions with distances below this value are considered static. sabi &lt;- sabi %&gt;% ungroup() %&gt;% mutate(static = stepMean &lt; mean(stepMean, na.rm = TRUE)) sabi_filter &lt;- sabi %&gt;% filter(!static) sabi_filter%&gt;% ggplot(aes(E, N)) + geom_path() + geom_point() + coord_fixed() + theme(legend.position = &quot;bottom&quot;) Figure 5: The trajectory of sabi, filtered to the positions where the animal was not static Task 1: Segmentation If you havent already done so open the RStudio Project you have prepared for this week. With the skills from the input above you can now implement the segmentation algorithm described in Laube and Purves (2011) on the dataset caro60.csv. Download this dataset (right click &gt; save target as) and import it as a simple data.frame or tibble (you dont need an sf-object for todays task). The sampling interval for this dataset is 1 minute. Use a temporal window \\(v\\) of 6 minutes, i.e. a window size of 6 positions (n±3). Once you have completed the task, commit your changes with a meaningful commit message and test your connection to Github by pushing your changes to your remote repository. Task 2: Specify and apply threshold d After calculating the Euclidean distances to positions within the temporal window v in task 1, you can explore these values (we stored them in the column stepMean) using summary statistics (histograms, boxplot, summary()): This way we can define a reasonable threshold value to differentiate between stops and moves. There is no correct way of doing this, specifying a threshold always depends on data as well as the question that needs to be answered. In this exercise, use the mean of all stepMean values. Store the new information (boolean to differentiate between stops (TRUE) and moves (FALSE)) in a new column named static. Commit your changes with a meaningful commit message. Task 3: Visualize segmented trajectories Now visualize the segmented trajectory spatially. Just like last week, you can use ggplot with geom_path(), geom_point() and coord_equal(). Assign colour = static within aes() to distinguish between segments with movement and without. Commit your changes with a meaningful commit message. Task 4: Segment-based analysis In applying Laube and Purves (2011), weve come as far as steps b in figure 3. In order to complete the last steps (c and d), we need a unique ID for each segment that we can use as a grouping variable. The following function does just that (it assigns unique IDs based on the column static which you created in Task 2). You will learn about functions next week. For now, just copy the following code chunk into your script and run it. rle_id &lt;- function(vec){ x &lt;- rle(vec)$lengths as.factor(rep(seq_along(x), times=x)) } You can use the newly created function rle_id to assign unique IDs to subtrajectories (as shown below). Visualize the moving segments by colourizing them by segment_ID. Then use segment_ID as a grouping variable to determine the segments duration and remove short segments (e.g. segments with a duration &lt; 5 Minutes) Commit your changes with a meaningful commit message. caro60 &lt;- caro60 %&gt;% mutate(segment_id = rle_id(static)) caro60 ## # A tibble: 200 x 9 ## TierID TierName CollarID DatetimeUTC E N stepMean static ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 010C Caro 13973 2015-09-15 08:07:00 2570589. 1.21e6 NA NA ## 2 010C Caro 13973 2015-09-15 08:08:00 2570573. 1.21e6 NA NA ## 3 010C Caro 13973 2015-09-15 08:09:00 2570536. 1.21e6 NA NA ## 4 010C Caro 13973 2015-09-15 08:10:00 2570518. 1.21e6 53.8 FALSE ## 5 010C Caro 13973 2015-09-15 08:11:00 2570499. 1.21e6 41.2 FALSE ## 6 010C Caro 13973 2015-09-15 08:12:00 2570489. 1.21e6 24.4 FALSE ## 7 010C Caro 13973 2015-09-15 08:13:00 2570482. 1.21e6 17.1 FALSE ## 8 010C Caro 13973 2015-09-15 08:14:00 2570481. 1.21e6 13.4 FALSE ## 9 010C Caro 13973 2015-09-15 08:15:00 2570486. 1.21e6 9.05 FALSE ## 10 010C Caro 13973 2015-09-15 08:16:00 2570490. 1.21e6 10.1 FALSE ## # ... with 190 more rows, and 1 more variable: segment_id &lt;fct&gt; Task 5: Similarity measures We will now leave the wild boar data and turn our attentian to human movement. You will use the dataset pedestrian.csv (right click &gt; save target as..) for this (and the following) task. Download an import this dataset as a data.frame or tibble. It it a set of six different but similar trajectories from pedestrians walking on a path. For this task, explore the trajectories first and get an idea on how the pedestrians moved. We step away from using the wild boar data for this task because our animals dont express the type of similarity we want to illustrate here. Also, using the constructed pedestrian data allows us illustrating very typical similarity issues, that are picked-up in different ways by the different similarity measures. In later exercises we will get back to our wild boar! Commit your changes with a meaningful commit message. Task 6: Calculate similarity Install the package SimilarityMeasures (install.packages(\"SimilarityMeasures\")). Familiarize yourself with this package by skimming through the function descriptions help(package = \"SimilarityMeasures\"). Now compare trajectory 1 to trajectories 2-6 using different similarity measures from the package. Your options are. DTW, EditDist, Frechet and LCSS. Visualize your results and try to understand the different results with respect to your reading of Alan Both (2018). Can you see connections between the properties of the trajectories and the similarity values computed by the different measures? Note: All functions in the package need matrices as input, with one trajectory per matrix. LCSStakes very long to compute. The accuracy of the algorithm (pointSpacing = ,pointDistance = and errorMarg =) can be varied to provide faster calculations. Please see Vlachos, Gunopoulos, and Kollios (2002) for more information. Commit your changes with a meaningful commit message. Now push all your changes to Github. Submission To submit your exercise, provide us with the URL of your Github repo as described in the preperation. "],["W3_5_peer_feedback.html", "Peer Feedback", " Peer Feedback For this weeks exercises, you will give each other peer feedback. We will assign each of you to review the submission of one of your classmates and provide you with the according Github URL. Once you have this URL, clone the repo to your local hard drive in the following manner: In RStudio, start a new project Choose: File &gt; New Project &gt; Version Control &gt; Git. In the repository URL, paste the URL from your classmate This will create a clone of that project on your local machine and open it in RStudio. You can now run the script of your classmate and think on how you would improve his or her solution. To provide your classmate with feedback to specific parts of the code, we recommend the following approach. Open your classmates repository on github.com Find and open the R / RMarkdown script containing the code you want to provide feedback on Highlight the lines you want to reference by clicking on the respective line numbers (you can select multiple lines by selecting the first line, holding the shift key and then selecting the last line) Click on the three dots situatied to the left of the first line Choose Reference in new issue. This will create a new issue with a link referencing the specific lines. Add your comment Issues is a great way to provide feedback on a codebase. Your classmate can now review your comment, provide an answer and close the issue once it is resolved. RStudio Addin Switching between RStudio and Github.com can be inefficient and cumbersome. We have therefore created an RStudio Addin to allow you to write issues directly from within RStudio. To use this addin, you will need to install it first with the following instruction: Install devtools (install.packages(\"devtools\")) Install inlineComments from Github (ComputationalMovementAnalysis/inlineComments, via devtools::install_github(\"ComputationalMovementAnalysis/inlineComments\")) Restart RStudio Click on tools &gt; Modify keyboard shortcuts and add a shortcut for the command Insert inline comment (e.g. Ctrl + Shift + k) Now for each comment, you can highlight the lines you wish to comment and use the keyboard shortcut you assigned in the last step (e.g. Ctrl + Shift + k). This should open a window where you can add your comment. If you hit Create issue, an issue will be added to your fellow students repo and a message will show you a link to the new issue. "],["W3_5_solutions.html", "Solutions", " Solutions Hover over the code and copy the content by clicking on the clipboard icon on the top right. You can now paste this into an R-Script. # task 1 ######################################################################## library(readr) library(dplyr) library(ggplot2) caro60 &lt;- read_delim(&quot;00_Rawdata/caro60.csv&quot;,&quot;,&quot;) caro60 &lt;- caro60 %&gt;% mutate( stepMean = rowMeans( cbind( sqrt((lag(E,3)-E)^2+(lag(E,3)-E)^2), sqrt((lag(E,2)-E)^2+(lag(E,2)-E)^2), sqrt((lag(E,1)-E)^2+(lag(E,1)-E)^2), sqrt((E-lead(E,1))^2+(E-lead(E,1))^2), sqrt((E-lead(E,2))^2+(E-lead(E,2))^2), sqrt((E-lead(E,3))^2+(E-lead(E,3))^2) ) ) ) # Note: # We present here a slightly different approach as presented in the input: # - cbind() creates a matrix with the same number of rows as the original dataframe # - It has 6 columns, one for each Euclidean distance calculation # - rowMeans() returns a single vector with the same number of rows as the original dataframe # task 2 ######################################################################## summary(caro60$stepMean) ggplot(caro60, aes(stepMean)) + geom_histogram(binwidth = 1) + geom_vline(xintercept = mean(caro60$stepMean,na.rm = TRUE)) caro60 &lt;- caro60 %&gt;% mutate( static = stepMean &lt; mean(caro60$stepMean,na.rm = TRUE) ) # task 3 ######################################################################## caro60 %&gt;% ggplot() + geom_path(aes(E,N), alpha = 0.5) + geom_point(aes(E,N,colour = static)) + theme_minimal() + coord_equal() # task 4 ######################################################################## caro60 &lt;-caro60 %&gt;% mutate( segment_ID = rle_id(static) ) caro60_moves &lt;- caro60 %&gt;% filter(!static) p1 &lt;- ggplot(caro60_moves, aes(E, N, color = segment_ID)) + geom_point() + geom_path() + coord_equal() + theme(legend.position = &quot;none&quot;) + labs(subtitle = &quot;All segments (uncleaned)&quot;) p2 &lt;- caro60_moves %&gt;% group_by(segment_ID) %&gt;% mutate(duration = as.integer(difftime(max(DatetimeUTC),min(DatetimeUTC),&quot;mins&quot;))) %&gt;% filter(duration &gt; 5) %&gt;% ggplot(aes(E, N, color = segment_ID))+ # geom_point(data = caro60, color = &quot;black&quot;) + geom_point() + geom_path() + coord_equal() + theme(legend.position = &quot;none&quot;) + labs(subtitle = &quot;Long segments (removed segements &lt;5 minutes)&quot;) # task 5 ######################################################################## pedestrians &lt;- read_delim(&quot;00_Rawdata/pedestrian.csv&quot;,&quot;,&quot;) ggplot(pedestrians, aes(E,N)) + geom_point(data = dplyr::select(pedestrians, -TrajID),alpha = 0.1) + geom_point(aes(color = as.factor(TrajID)), size = 2) + geom_path(aes(color = as.factor(TrajID))) + facet_wrap(~TrajID,labeller = label_both) + coord_equal() + theme_minimal() + labs(title = &quot;Visual comparison of the 6 trajectories&quot;, subtitle = &quot;Each subplot highlights a trajectory&quot;) + theme(legend.position = &quot;none&quot;) # task 6 ######################################################################## library(SimilarityMeasures) # for the similarity measure functions # all functions compare two trajectories (traj1 and traj2). Each trajectory # must be an numeric matrix of n dimensions. Since our dataset is spatiotemporal # we need to turn our Datetime column from POSIXct to integer: pedestrians &lt;- pedestrians %&gt;% mutate(Datetime_int = as.integer(DatetimeUTC)) # Next, we make an object for each trajectory only containing the # coordinates in the three-dimensional space and turn it into a matrix traj1 &lt;- pedestrians %&gt;% filter(TrajID == 1) %&gt;% dplyr::select(E, N, Datetime_int) %&gt;% as.matrix() # But instead of repeating these lines 6 times, we turn them into a function. # (this is still more repetition than necessary, use the purr::map if you know # how!) df_to_traj &lt;- function(df, traj){ df %&gt;% filter(TrajID == traj) %&gt;% dplyr::select(E, N, Datetime_int) %&gt;% as.matrix() } traj2 &lt;- df_to_traj(pedestrians, 2) traj3 &lt;- df_to_traj(pedestrians, 3) traj4 &lt;- df_to_traj(pedestrians, 4) traj5 &lt;- df_to_traj(pedestrians, 5) traj6 &lt;- df_to_traj(pedestrians, 6) # Then we can start comparing trajectories with each other dtw_1_2 &lt;- DTW(traj1, traj2) dtw_1_3 &lt;- DTW(traj1, traj3) # ... and so on. Since this also leads to much code repetition, we will # demostrate a diffferent approach: # Instead of creating 6 objects, we can also create a single list containing 6 # elements by using &quot;split&quot; and &quot;purrr::map&quot; library(purrr) pedestrians_list &lt;- map(1:6, function(x){ df_to_traj(pedestrians,x) }) comparison_df &lt;- map_dfr(2:6, function(x){ tibble( trajID = x, DTW = DTW(pedestrians_list[[1]], pedestrians_list[[x]]), EditDist = EditDist(pedestrians_list[[1]], pedestrians_list[[x]]), Frechet = Frechet(pedestrians_list[[1]], pedestrians_list[[x]]), LCSS = LCSS(pedestrians_list[[1]], pedestrians_list[[x]],5,4,4) ) }) library(tidyr) # for pivot_longer comparison_df %&gt;% pivot_longer(-trajID) %&gt;% ggplot(aes(trajID,value, fill = as.factor(trajID)))+ geom_bar(stat = &quot;identity&quot;) + facet_wrap(~name,scales = &quot;free&quot;) + theme(legend.position = &quot;none&quot;) + labs(x = &quot;Comparison trajectory&quot;, y = &quot;Value&quot;, title = &quot;Computed similarities using different measures \\nbetween trajectory 1 to all other trajectories &quot;) "],["W4_1_exercise.html", "Exercise 4", " Exercise 4 Learning Outcomes* You are able to conceptualize a simple movement pattern and implement data structures and corresponding procedures (lets call them algorithms) for detecting it using R. You understand the sensitivity of movement patterns to pattern parameter thresholds. "],["W4_2_Slides.html", "Slides", " Slides Slides for Nils and Nikos Input: "],["W4_3_preparation.html", "Preparation", " Preparation Create a new RStudio Project and a new Github Repo for this weeks exercises. Do this either the simple way we used in Exercise 2 (Step 3 and then Step 4) or the more sophisticated way we suggested in Exercise 3. If you want to publish your Report as a website (to share with others), activate Github Pages by going to your repo on Github, clicking on Settings &gt; Pages, and under Source switch from None to your Main branch. You can do this only after pushing your first commit. "],["W4_4_tasks_and_inputs.html", "Tasks and inputs", " Tasks and inputs Up to now, we have used a variety of different functions designed by other developers. Sometimes we need to execute an operation multiple times, and most often it is reasonable to write a function to do so. Whenever you have copied and pasted a block of code more than twice, you should consider writing a function (Wickham and Grolemund 2017). We have violated this rule multiple times when calculating the Euclidean distances between points. Writing and rewriting the code sqrt((x-lead(x,1))^2+(y-lead(y,1))^2) over and over again is not only cumbersome, it is also error prone. We can easily wrap this operation into a function. This input on writing functions should bring you up to speed to do this in your first task. The first step in writing a function, is picking a name and assigning &lt;- function(){} to it. testfun &lt;- function(){} To run the function, we have to call the assigned name with the brackets. This function gives no output, which is why we get NULL back. testfun() ## NULL class(testfun) ## [1] &quot;function&quot; To make the function actually do something, we need to specify what should be done within the curly brackets {}. The following function always prints the same statement and accepts no input values: testfun &lt;- function(){print(&quot;this function does nothing&quot;)} testfun() ## [1] &quot;this function does nothing&quot; If we want the function to accept some input values, we have to define them within the round brackets. For example, I specify a variable named sometext and can call this variable within the execution. testfun &lt;- function(sometext){print(sometext)} testfun(sometext = &quot;this function does slightly more, but still not much&quot;) ## [1] &quot;this function does slightly more, but still not much&quot; Lets take a more practical example. Say we want a function that calculates our age if provided with the date of our birthday. We can use Sys.time() to provide todays date and difftime() to calculate the time difference between today and our birthday. my_age &lt;- function(birthday, units){ difftime(Sys.time(),birthday, units = units) } my_age(birthday = &quot;1997-04-23&quot;, units = &quot;days&quot;) ## Time difference of 9170.595 days As we already know from using other functions, if we declare our variables in the order that we initially listed them, we do not need to specify the parameters (no need of birthday = and units =). my_age(&quot;1997-04-23&quot;, &quot;days&quot;) ## Time difference of 9170.595 days If we want any of our parameters to have default value, we can assign an initial value to the parameter when declaring the variables within the round brackets. my_age &lt;- function(birthday, units = &quot;days&quot;){ difftime(Sys.time(),birthday, units = units) } # if not stated otherwise, our function uses the unit &quot;days&quot; my_age(&quot;1997-04-23&quot;) ## Time difference of 9170.595 days # We can still overwrite units my_age(&quot;1997-04-23&quot;, &quot;hours&quot;) ## Time difference of 220094.3 hours All you need to do now is run execute the function deceleration (myage &lt;- function... etc.) at the beginning of your script, and you can use the function for your entire R session. Tip: Always try to make your function self sufficient: Dont call variables that were created outside the function call. Task 1: Write your own functions Create a function for our Euclidean distance calculation. Note: if you treat your input variables as vectors, they will work in dplyrs mutate() and summarise() operations. Task 2: Prepare Analysis In the next tasks we will look for meet patterns in our wildboar data. To simplify this, we will only use a subset of our wildboar data: The individuals Rosa and Sabi for the timespan 01.04.2015 - 15.04.2015. You can download the dataset here wildschwein_BE_2056.csv (right click &gt; save target as) and filter it with the aforementioned criteria. Remember to load the necessary libraries first! We propose the following: library(readr) library(dplyr) library(ggplot2) library(lubridate) Task 3: Create Join Key Have a look at your dataset. You will notice that samples are taken at every full hour, quarter past, half past and quarter to. The sampling time is usually off by a couple of seconds. To compare Rosa and Sabis locations, we first need to match the two animals temporally. For that we can use a join, but need identical time stamps to serve as a join key. We therefore need to slightly adjust our time stamps to a common, concurrent interval. The task is therfore to round the minutes of DatetimeUTC to a multiple of 15 (00, 15, 30,45) and store the values in a new column5. You can use the lubridate function round_date() for this. See the examples here to see how this goes. Your new dataset should look something like this (note the additional column): ## # A tibble: 6 x 7 ## # Groups: TierID [1] ## TierID TierName CollarID DatetimeUTC E N DatetimeRound ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; ## 1 002A Sabi 12275 2015-03-31 22:00:28 2.57e6 1.21e6 2015-03-31 22:00:00 ## 2 002A Sabi 12275 2015-03-31 22:15:44 2.57e6 1.21e6 2015-03-31 22:15:00 ## 3 002A Sabi 12275 2015-03-31 22:30:44 2.57e6 1.21e6 2015-03-31 22:30:00 ## 4 002A Sabi 12275 2015-03-31 22:46:04 2.57e6 1.21e6 2015-03-31 22:45:00 ## 5 002A Sabi 12275 2015-03-31 23:00:17 2.57e6 1.21e6 2015-03-31 23:00:00 ## 6 002A Sabi 12275 2015-03-31 23:15:12 2.57e6 1.21e6 2015-03-31 23:15:00 Task 4: Measuring distance at concurrent locations To measure the distance between concurrent locations, we need to follow the following steps. Split the wildschwein_filter object into one data.frame per animal Join* these datasets by the new Datetime column created in the last task. The joined observations are temporally close. In the joined dataset, calculate Euclidean distances between concurrent observations and store the values in a new column Use a reasonable threshold on distance to determine if the animals are also spatially close enough to constitute a meet (we use 100 meters). Store this Boolean information (TRUE/FALSE) in a new column * We recommend using one dplyrs join methods (inner_join(), left_join(), right_join() or full_join()), which one is appropriate? Tip: specify suffix to prevent column names ending in .x or .y. Task 5: Visualize data Now, visualize the meets spatially in a way that you think reasonable. For example in the plot as shows below. To produce this plot we: Used the individual dataframes from rosa and sabi (from the previous task) Used the joined dataset (also from the previous task), filtered to only the meets Manually changed the x and y axis limits Task 6 (optional): Visualize data as timecube with plotly Finally, you can nicely visualize the meeting patterns and trajectories in a Space-Time-Cube (Hägerstraand 1970) with the package plotly. There are some nice ressources available online. Please note: We are manipulating our time stamps without adjusting the x,y-coordinates. This is fine for our simple example, but we would advice against this in a more serious research endeavour, e.g. in your semester projects. One simple approach would be to linearly interpolate the positions to the new timestamps. If you choose Option A the wild boar projects as your semester projects, you should aim for a linear interpolation. Get in touch if you need help with this. "],["W5_1_exercise.html", "Exercise 5", " Exercise 5 Learning Outcomes You are able to process spatial data (vector and raster) within R, including creating simple maps within R. You know basic operations for semantically annotating your trajectories with geographic context. "],["W5_2_preparation.html", "Preparation", " Preparation Create a new RStudio Project and a new Github Repo for this weeks exercises. Do this either the simple way we used in Exercise 2 (Step 3 and then Step 4) or the more sophisticated way we suggested in Exercise 3. If you want to publish your Report as a website (to share with others), activate Github Pages by going to your repo on Github, clicking on Settings &gt; Pages, and under Source switch from None to your Main branch. You can do this only after pushing your first commit. "],["W5_3_tasks_and_inputs.html", "Tasks and Inputs", " Tasks and Inputs Open your RStudio Project which you prepared from this week. Create a new RScript and import the libraries we need for this week. Import your wildboar dataset wildschwein_BE_2056.csv as an sf object library(readr) library(sf) library(terra) library(dplyr) library(lubridate) library(ggplot2) library(tmap) wildschwein_BE &lt;- read_delim(&quot;00_Rawdata/wildschwein_BE_2056.csv&quot;,&quot;,&quot;) %&gt;% st_as_sf(coords = c(&quot;E&quot;, &quot;N&quot;), crs = 2056, remove = FALSE) Download the dataset Feldaufnahmen_Fanel.gpkg and save it to your project folder. This is a vector dataset stored in the filetype Geopackage, which is similar to a Shapefile, with some advantages (see the website shapefile must die). Also download the dataset vegetationshoehe_LFI.tif. This is a raster dataset stored in a Geotiff, similar to the map we imported in week 1. Also store this file in your project folder and commit these to your repo. Tasks 1: Import and visualize spatial data Since Feldaufnahmen_Fanel.gpkg is a vector dataset, you can import it using read_sf(). Explore this dataset in R to answer the following questions: What information does the dataset contain? What is the geometry type of the dataset (possible types are: Point, Lines and Polygons)? What are the data types of the other columns? What is the coordinate system of the dataset? Task 2: Annotate Trajectories from vector data We would like to know what crop was visited by which wild boar, and at what time. Since the crop data is most relevant in summer, filter your wildboar data to the months may to june first and save the output to a new variable. Overlay the filtered dataset with your fanel data to verify the spatial overlap. To sematically annotate each wildboar location with crop information, you can use a spatial join with the function st_join(). Do this and explore your annotated dataset. Task 3: Explore annotated trajectories Think of ways you could visually explore the spatio-temporal patterns of wild boar in relation to the crops. In our example below we visualize the percentage of samples in a given crop per hour. Task 4: Import and visualize vegetationindex (raster data) You have already downloaded the dataset vegetationshoehe_LFI.tif. Import this dataset In terms of raster data, we have prepared the Vegetation Height Model provided by the Swiss National Forest Inventory (NFI). This dataset contains high resolution information (1x1 Meter) on the vegetation height, which is determined from the difference between the digital surface models DSM and the digital terrain model by swisstopo (swissAlti3D). Buildings are eliminated using a combination of the ground areas of the swisstopo topographic landscape model (TLM) and spectral information from the stereo aerial photos. Import the dataset just like you imported the raster map in week 1 (using terra::rast()). Visualize the raster data using tmap (ggplot is very slow with raster data). Task 5: Annotate Trajectories from raster data Semantically annotate your wildboar locations with the vegetation index (similar as you did with the crop data in Task 2). Since you are annotating a vector dataset with information from a raster dataset, you cannot use st_join but need the function extract from the terra package. Read the help on the extract function to see what the function expects. The output should look something like this: ## Simple feature collection with 51246 features and 7 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 2568153 ymin: 1202306 xmax: 2575154 ymax: 1207609 ## Projected CRS: CH1903+ / LV95 ## First 10 features: ## TierID TierName CollarID DatetimeUTC E N ## 1 002A Sabi 12275 2014-08-22 21:00:12 2570409 1204752 ## 2 002A Sabi 12275 2014-08-22 21:15:16 2570402 1204863 ## 3 002A Sabi 12275 2014-08-22 21:30:43 2570394 1204826 ## 4 002A Sabi 12275 2014-08-22 21:46:07 2570379 1204817 ## 5 002A Sabi 12275 2014-08-22 22:00:22 2570390 1204818 ## 6 002A Sabi 12275 2014-08-22 22:15:10 2570390 1204825 ## 7 002A Sabi 12275 2014-08-22 22:30:13 2570387 1204831 ## 8 002A Sabi 12275 2014-08-22 22:45:11 2570381 1204840 ## 9 002A Sabi 12275 2014-08-22 23:00:27 2570316 1204935 ## 10 002A Sabi 12275 2014-08-22 23:15:41 2570393 1204815 ## vegetationshoehe_LFI geometry ## 1 20.09 POINT (2570409 1204752) ## 2 23.85 POINT (2570402 1204863) ## 3 24.96 POINT (2570394 1204826) ## 4 21.59 POINT (2570379 1204817) ## 5 15.68 POINT (2570390 1204818) ## 6 23.77 POINT (2570390 1204825) ## 7 25.09 POINT (2570387 1204831) ## 8 24.88 POINT (2570381 1204840) ## 9 29.91 POINT (2570316 1204935) ## 10 21.52 POINT (2570393 1204815) You can now explore the spatiotemporal patterns of this new data. "],["90_references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
